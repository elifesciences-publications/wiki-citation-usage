{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### string lengths of Wikipedia pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import re\n",
    "import pyspark.sql\n",
    "from pyspark.sql import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "import os.path\n",
    "from pyspark.sql.functions import desc\n",
    "from datetime import timedelta, date\n",
    "from pyspark import *\n",
    "\n",
    "%matplotlib inline\n",
    "spark_hive = pyspark.sql.HiveContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKIPEDIA_XML_DUMP = 'enwiki-20190420-pages-articles-multistream.xml.bz2'\n",
    "\n",
    "def page_length(entity):\n",
    "    page_text = entity.revision.text._VALUE\n",
    "    size = len(page_text)\n",
    "    return Row(page_id=entity.id, page_length=size)\n",
    "\n",
    "wikipedia = sqlContext.read.format('com.databricks.spark.xml').options(rowTag='page').load(WIKIPEDIA_XML_DUMP)\n",
    "\n",
    "articles = wikipedia\\\n",
    "    .filter(\"ns = '0'\")\\\n",
    "    .filter(\"redirect._title is null\") \\\n",
    "    .filter(\"revision.text._VALUE is not null\") \\\n",
    "    .filter(\"length(revision.text._VALUE) > 0\")\n",
    "\n",
    "page_lengths = sqlContext.createDataFrame(articles.rdd.map(page_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|page_id|page_length|\n",
      "+-------+-----------+\n",
      "|     12|     102191|\n",
      "|     25|     135250|\n",
      "|     39|      43966|\n",
      "|    290|      25311|\n",
      "|    303|     183922|\n",
      "|    305|      73305|\n",
      "|    307|     168733|\n",
      "|    308|     138869|\n",
      "|    309|      19905|\n",
      "|    316|      96065|\n",
      "|    324|     104397|\n",
      "|    330|       5841|\n",
      "|    332|       6389|\n",
      "|    334|      12895|\n",
      "|    336|      67605|\n",
      "|    339|      90900|\n",
      "|    340|       7512|\n",
      "|    344|      12659|\n",
      "|    358|     145728|\n",
      "|    359|      32578|\n",
      "+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "page_lengths.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write page lengths data to a table for later use\n",
    "page_lengths.createOrReplaceTempView(\"temp_page_lengths\")\n",
    "sqlContext.sql(\"DROP TABLE IF EXISTS ryanmax.page_lengths\")\n",
    "sqlContext.sql(\"CREATE TABLE ryanmax.page_lengths AS SELECT * FROM temp_page_lengths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date ranges for queries\n",
    "start_date = date(2019, 3, 29)\n",
    "end_date = date(2019, 4, 22)\n",
    "date_format = '%Y-%m-%d'\n",
    "start_date_string = start_date.strftime(date_format)\n",
    "end_date_string = end_date.strftime(date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+---------------+\n",
      "|average_page_length|median_page_length|stddev_page_length|iqr_page_length|\n",
      "+-------------------+------------------+------------------+---------------+\n",
      "|            7718.31|            3881.0| 13695.01314943199|         5826.0|\n",
      "+-------------------+------------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# page_lengths of W pages w/ ext links\n",
    "w_pl_query = \"\"\"\n",
    "SELECT CAST(AVG(page_length) AS DECIMAL(10,2)) AS average_page_length, \n",
    "    PERCENTILE(page_length,0.5) AS median_page_length,\n",
    "    STDDEV(page_length) as stddev_page_length,\n",
    "    (PERCENTILE(page_length,0.75) - PERCENTILE(page_length,0.25)) as iqr_page_length\n",
    "FROM \n",
    "    ryanmax.page_lengths\n",
    "WHERE page_id IN \n",
    "    (SELECT DISTINCT page_id \n",
    "    FROM ryanmax.pages_with_extlinks \n",
    "    WHERE to_date(dt) = '{}' AND to_date(dt) <= '{}')\n",
    "\"\"\"\n",
    "\n",
    "w_pl_links = spark.sql(w_pl_query.format(start_date_string, end_date_string))\n",
    "w_pl_links.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+---------------+\n",
      "|average_page_length|median_page_length|stddev_page_length|iqr_page_length|\n",
      "+-------------------+------------------+------------------+---------------+\n",
      "|           13073.98|            6618.0|19366.759391823256|        11638.0|\n",
      "+-------------------+------------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# page_lengths of WP:M pages w/ ext links\n",
    "pm_pl_query = \"\"\"\n",
    "SELECT CAST(AVG(page_length) AS DECIMAL(10,2)) AS average_page_length, \n",
    "    PERCENTILE(page_length,0.5) AS median_page_length,\n",
    "    STDDEV(page_length) as stddev_page_length,\n",
    "    (PERCENTILE(page_length,0.75) - PERCENTILE(page_length,0.25)) as iqr_page_length\n",
    "FROM \n",
    "    ryanmax.page_lengths\n",
    "WHERE page_id IN \n",
    "    (SELECT DISTINCT page_id \n",
    "    FROM ryanmax.projmed_with_extlinks \n",
    "    WHERE to_date(dt) >= '{}' AND to_date(dt) <= '{}')\n",
    "\"\"\"\n",
    "\n",
    "pm_pl_links = spark.sql(pm_pl_query.format(start_date_string, end_date_string))\n",
    "pm_pl_links.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+---------------+\n",
      "|average_page_length|median_page_length|stddev_page_length|iqr_page_length|\n",
      "+-------------------+------------------+------------------+---------------+\n",
      "|            7675.84|            3865.0|13634.502758611616|         5788.0|\n",
      "+-------------------+------------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# page_lengths of not WP:M pages w/ ext links\n",
    "not_pm_pl_query = \"\"\"\n",
    "SELECT CAST(AVG(page_length) AS DECIMAL(10,2)) AS average_page_length, \n",
    "    PERCENTILE(page_length,0.5) AS median_page_length,\n",
    "    STDDEV(page_length) as stddev_page_length,\n",
    "    (PERCENTILE(page_length,0.75) - PERCENTILE(page_length,0.25)) as iqr_page_length\n",
    "FROM \n",
    "    ryanmax.page_lengths\n",
    "WHERE page_id IN \n",
    "    (SELECT DISTINCT page_id \n",
    "    FROM ryanmax.pages_with_extlinks \n",
    "    WHERE to_date(dt) >= '{}' AND to_date(dt) <= '{}')\n",
    "    AND page_id NOT IN \n",
    "    (SELECT DISTINCT page_id \n",
    "    FROM ryanmax.projmed_with_extlinks \n",
    "    WHERE to_date(dt) >= '{}' AND to_date(dt) <= '{}')\n",
    "\"\"\"\n",
    "\n",
    "not_pm_pl_links = spark.sql(\n",
    "    not_pm_pl_query.format(start_date_string, end_date_string, start_date_string, end_date_string))\n",
    "not_pm_pl_links.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark Custom: spark-xml jar and local venv path ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
